\contentsline {section}{Abstract{} }{ii}{section*.1}
\contentsline {section}{Preface}{iii}{section*.2}
\contentsline {section}{Contents}{iv}{section*.3}
\contentsline {section}{Symbols and abbreviations*}{vi}{section*.5}
\select@language {english}
\contentsline {section}{\numberline {1}Introduction*}{2}{section.1}
\contentsline {subsection}{\numberline {1.1}Motivation*}{2}{subsection.1.1}
\contentsline {subsection}{\numberline {1.2}Structure of the thesis*}{2}{subsection.1.2}
\contentsline {section}{\numberline {2}Context *}{3}{section.2}
\contentsline {subsection}{\numberline {2.1}Background *}{3}{subsection.2.1}
\contentsline {subsection}{\numberline {2.2}Corporate Partner}{3}{subsection.2.2}
\contentsline {subsection}{\numberline {2.3}Need Statement *}{3}{subsection.2.3}
\contentsline {subsection}{\numberline {2.4}Problem Statement *}{3}{subsection.2.4}
\contentsline {subsection}{\numberline {2.5}Research objectives *}{3}{subsection.2.5}
\contentsline {subsection}{\numberline {2.6}Related work *-}{3}{subsection.2.6}
\contentsline {section}{\numberline {3}Research Process and Design Development (*)}{5}{section.3}
\contentsline {subsection}{\numberline {3.1}Crowdsourced Data Collection (*)}{5}{subsection.3.1}
\contentsline {subsubsection}{\numberline {3.1.1}Explorative Paragraph Dataset}{5}{subsubsection.3.1.1}
\contentsline {subsubsection}{\numberline {3.1.2}Sentence Data Collection}{6}{subsubsection.3.1.2}
\contentsline {section}{\numberline {4}Background}{10}{section.4}
\contentsline {subsection}{\numberline {4.1}Evaluation}{10}{subsection.4.1}
\contentsline {subsubsection}{\numberline {4.1.1}Binary Classification}{10}{subsubsection.4.1.1}
\contentsline {paragraph}{Accuracy}{10}{section*.32}
\contentsline {paragraph}{Precision, Recall and F1 Score}{11}{section*.33}
\contentsline {paragraph}{Informedness, Markedness and Matthews Correlation Coefficient}{12}{section*.34}
\contentsline {paragraph}{Cross-Entropy}{12}{section*.35}
\contentsline {subsubsection}{\numberline {4.1.2}Multi-class Classification}{13}{subsubsection.4.1.2}
\contentsline {paragraph}{Averaging for Multi-class Recall, Precision and F1-Score}{13}{section*.38}
\contentsline {paragraph}{Matthews Correlation Coefficient for K classes}{14}{section*.39}
\contentsline {paragraph}{Categorical Cross-Entropy}{15}{section*.40}
\contentsline {subsubsection}{\numberline {4.1.3}Multi-label Classification *}{15}{subsubsection.4.1.3}
\contentsline {subsection}{\numberline {4.2}Language Modeling}{15}{subsection.4.2}
\contentsline {subsubsection}{\numberline {4.2.1}Vector Space Language Models}{15}{subsubsection.4.2.1}
\contentsline {subsubsection}{\numberline {4.2.2}N-gram language models}{16}{subsubsection.4.2.2}
\contentsline {paragraph}{Variants}{16}{section*.46}
\contentsline {subparagraph}{Words vs. Characters}{16}{section*.48}
\contentsline {subparagraph}{Stop words}{16}{section*.49}
\contentsline {subparagraph}{N-gram range}{17}{section*.50}
\contentsline {subparagraph}{Vector size}{17}{section*.51}
\contentsline {subparagraph}{TF.IDF weighting}{17}{section*.52}
\contentsline {subparagraph}{Sublinear TF scaling}{17}{section*.53}
\contentsline {subparagraph}{Normalization}{17}{section*.54}
\contentsline {paragraph}{Shortcomings}{17}{section*.56}
\contentsline {subsubsection}{\numberline {4.2.3}Language Models using Distributed Representations}{18}{subsubsection.4.2.3}
\contentsline {paragraph}{Simplified Continuous Models}{19}{section*.58}
\contentsline {subparagraph}{Hierarchical Sampling}{20}{section*.61}
\contentsline {subparagraph}{Negative Sampling}{20}{section*.62}
\contentsline {subparagraph}{Frequent word sub-sampling}{20}{section*.63}
\contentsline {paragraph}{Distributed representations for documents}{20}{section*.64}
\contentsline {subparagraph}{Bag-of-Means}{20}{section*.65}
\contentsline {subparagraph}{Parse Trees}{20}{section*.66}
\contentsline {subparagraph}{Paragraph Vectors}{21}{section*.67}
\contentsline {subsection}{\numberline {4.3}Classification Approaches}{21}{subsection.4.3}
\contentsline {subsubsection}{\numberline {4.3.1}Approaches to Multi-class Classification}{21}{subsubsection.4.3.1}
\contentsline {section}{\numberline {5}Explorative Experiments with Paragraph Dataset}{22}{section.5}
\contentsline {section}{\numberline {6}Experiments with Sentence Dataset}{22}{section.6}
\contentsline {subsection}{\numberline {6.1}Vector Space Models compared}{22}{subsection.6.1}
\contentsline {subsubsection}{\numberline {6.1.1}Baselines Classifiers: Uniform and Stratified Guessing}{22}{subsubsection.6.1.1}
\contentsline {subsubsection}{\numberline {6.1.2}N-gram Language Models}{22}{subsubsection.6.1.2}
\contentsline {paragraph}{Type}{24}{section*.80}
\contentsline {paragraph}{Range}{24}{section*.81}
\contentsline {paragraph}{Stop Words}{25}{section*.82}
\contentsline {paragraph}{Size (matters)}{25}{section*.83}
\contentsline {paragraph}{IDF}{25}{section*.84}
\contentsline {paragraph}{Norm}{25}{section*.85}
\contentsline {paragraph}{Sub-linear TF}{25}{section*.86}
\contentsline {subsubsection}{\numberline {6.1.3}Bag-of-Means - An Averaged Word2Vec Model}{26}{subsubsection.6.1.3}
\contentsline {subsubsection}{\numberline {6.1.4}Paragraph Vectors using Distributed Representations}{27}{subsubsection.6.1.4}
\contentsline {paragraph}{Vector Size *}{28}{section*.95}
\contentsline {paragraph}{Frequent word Sub-Sampling *}{28}{section*.96}
\contentsline {paragraph}{Hierarchical Sampling *}{28}{section*.97}
\contentsline {paragraph}{Negative Sampling *}{28}{section*.98}
\contentsline {paragraph}{Window Size *}{28}{section*.99}
\contentsline {paragraph}{CBOW versus PM-DV *}{28}{section*.100}
\contentsline {paragraph}{Evaluating the best hyper-parameter setting *}{28}{section*.101}
\contentsline {subsubsection}{\numberline {6.1.5}Paragraph Vectors using pre-initialized weights *}{29}{subsubsection.6.1.5}
\contentsline {subsubsection}{\numberline {6.1.6}Paragraph Vectors using context sentences *}{29}{subsubsection.6.1.6}
\contentsline {subsubsection}{\numberline {6.1.7}Results and Discussion *}{29}{subsubsection.6.1.7}
\contentsline {subsection}{\numberline {6.2}Finding the best Classifier using Vector Space Models}{29}{subsection.6.2}
\contentsline {subsection}{\numberline {6.3}Advanced and experimental approaches}{29}{subsection.6.3}
\contentsline {subsubsection}{\numberline {6.3.1}Inversion of Distributed Language Representations}{29}{subsubsection.6.3.1}
\contentsline {subsubsection}{\numberline {6.3.2}LSTM Multi-task learner}{29}{subsubsection.6.3.2}
\contentsline {section}{\numberline {7}Discussion and Conclusions}{30}{section.7}
\contentsline {subsection}{\numberline {7.1}Discussion of Experimental Results}{30}{subsection.7.1}
\contentsline {subsection}{\numberline {7.2}Conclusions}{30}{subsection.7.2}
\contentsline {subsection}{\numberline {7.3}Contributions}{30}{subsection.7.3}
\contentsline {subsection}{\numberline {7.4}Proposal for Future Research}{30}{subsection.7.4}
\contentsline {subsection}{\numberline {7.5}Learnings}{31}{subsection.7.5}
\contentsline {section}{References}{32}{section*.102}
