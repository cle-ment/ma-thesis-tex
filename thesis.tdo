\contentsline {todo}{one-hot or one-of-$V$ encoding}{vi}{section*.9}
\contentsline {todo}{section on transfer learning and feature learning}{3}{section*.11}
\contentsline {todo}{text classification}{3}{section*.12}
\contentsline {todo}{Multitask learning}{3}{section*.13}
\contentsline {todo}{explicit vs implicit feature representation}{3}{section*.14}
\contentsline {todo}{Describe data format}{4}{section*.15}
\contentsline {todo}{Picture of software setup?}{4}{section*.16}
\contentsline {todo}{Describe data: Different characteristics}{5}{section*.18}
\contentsline {todo}{show distribution?}{5}{section*.19}
\contentsline {todo}{show embedding visualizations}{5}{section*.20}
\contentsline {todo}{explain suervised classifiaction and binaty vs multi}{9}{section*.25}
\contentsline {todo}{citation for Confusion Matrix?}{11}{section*.27}
\contentsline {todo}{write vector space models introduction}{12}{section*.29}
\contentsline {todo}{explain language modeling as approach for text classification}{12}{section*.30}
\contentsline {todo}{is the term language model right for ngram vector space models?}{12}{section*.31}
\contentsline {todo}{example with 2 vectors and showing what they encode?}{12}{section*.32}
\contentsline {todo}{citation for first or review paper here?}{12}{section*.33}
\contentsline {todo}{mention GloVe}{16}{section*.45}
\contentsline {todo}{averaging }{17}{section*.49}
\contentsline {todo}{parse trees (socher}{17}{section*.50}
\contentsline {todo}{doc2vec}{17}{section*.51}
\contentsline {todo}{Comparison one-vs-rest and one-vs-one against linear machine}{18}{section*.53}
\contentsline {todo}{Visualizations and embeddings of data in 2D (and decision boundaries?)}{18}{section*.54}
\contentsline {todo}{show T-SNE embeddings of doc2vec vectors}{18}{section*.55}
\contentsline {todo}{say why using the sentence dataset here}{18}{section*.56}
\contentsline {todo}{reference jupyter notebook here}{18}{section*.57}
\contentsline {todo}{actually discuss time and memory requirements}{18}{section*.58}
\contentsline {todo}{reference section here}{18}{section*.59}
\contentsline {todo}{link to logistic regression classifier explanation here}{18}{section*.60}
\contentsline {todo}{link MCC multi here}{18}{section*.61}
\contentsline {todo}{show T-SNE embeddings of doc2vec vectors}{19}{section*.65}
\contentsline {todo}{show influence of each parameter on the performance by fixing it to each value it can take and measuring the variance of the results? or by just showing the mean when fixing to one value}{19}{section*.66}
\contentsline {todo}{Add list of english stop words used for ngrams (sklearn list)}{25}{section*.69}
\contentsline {todo}{Add first Ngram TF.IDF experiment}{25}{section*.70}
